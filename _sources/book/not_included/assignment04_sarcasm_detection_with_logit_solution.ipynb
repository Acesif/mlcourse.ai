{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9f76799",
   "metadata": {},
   "source": [
    "(assignment04_extra_solution)=\n",
    "\n",
    "\n",
    "# Assignment 4 (demo). Solution. Sarcasm detection with logistic regression\n",
    "\n",
    "\n",
    "```{figure} /_static/img/ods_stickers.jpg\n",
    "```\n",
    "\n",
    "Author: [Yury Kashnitsky](https://www.linkedin.com/in/festline/). All content is distributed under the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license.\n",
    "\n",
    "\n",
    "**Same assignment as a [Kaggle Notebook](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit) + [solution](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit-solution).**\n",
    "\n",
    "\n",
    "We'll be using the dataset from the [paper](https://arxiv.org/abs/1704.05579) \"A Large Self-Annotated Corpus for Sarcasm\" with >1mln comments from Reddit, labeled as either sarcastic or not. A processed version can be found on Kaggle in a form of a [Kaggle Dataset](https://www.kaggle.com/danofer/sarcasm).\n",
    "\n",
    "Sarcasm detection is easy.\n",
    "\n",
    "\n",
    "```{figure} /_static/img/yeah.jpeg\n",
    ":width: 400px\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75f7dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some necessary imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d27a4e",
   "metadata": {},
   "source": [
    "The dataset is a bit too large to be stored on GitHub. So, we download it from Google Drive. Alternatively, you can download the \"train-balanced-sarcasm.csv.zip\" file from [Kaggle](https://www.kaggle.com/danofer/sarcasm?select=train-balanced-sarcasm.csv.zip) ([alternative link](https://drive.google.com/file/d/1KbBdJaEY8RF4GXzoihWgH0RdqoVBZ_oi/view?usp=sharing)) and place the file in a convenient place, then modify the `DATA_PATH` below accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f6f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_from_gdrive(file_url, filename, out_path='../../_static', overwrite=False):\n",
    "    \"\"\"\n",
    "    Downloads a file from GDrive given an URL\n",
    "    :param file_url: a string formated as https://drive.google.com/uc?id=<file_id>\n",
    "    :param: the desired file name\n",
    "    :param: the desired folder where the file will be downloaded to\n",
    "    :param overwrite: whether to overwrite the file if it already exists\n",
    "    \"\"\"\n",
    "\n",
    "    file_exists = os.path.exists(f'{out_path}/{filename}')\n",
    "\n",
    "    if (file_exists and overwrite) or (not file_exists):\n",
    "    \tos.system(f'gdown {file_url} -O {out_path}/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce2e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_URL = 'https://drive.google.com/uc?id=1KbBdJaEY8RF4GXzoihWgH0RdqoVBZ_oi'\n",
    "FILE_NAME = 'train-balanced-sarcasm.csv.zip'\n",
    "DATA_PATH = '../../_static/data/'\n",
    "\n",
    "download_file_from_gdrive(file_url=FILE_URL, filename= FILE_NAME, out_path=DATA_PATH)\n",
    "\n",
    "train_df = pd.read_csv(DATA_PATH + \"train-balanced-sarcasm.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2506b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10d693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d0ca9d",
   "metadata": {},
   "source": [
    "Some comments are missing, so we drop the corresponding rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827f8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(subset=[\"comment\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ba3b6a",
   "metadata": {},
   "source": [
    "We notice that the dataset is indeed balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c341ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad48031",
   "metadata": {},
   "source": [
    "We split data into training and validation parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb968b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, valid_texts, y_train, y_valid = train_test_split(\n",
    "    train_df[\"comment\"], train_df[\"label\"], random_state=17\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5ed13",
   "metadata": {},
   "source": [
    "## Tasks:\n",
    "1. Analyze the dataset, make some plots. This [Kernel](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc) might serve as an example\n",
    "2. Build a Tf-Idf + logistic regression pipeline to predict sarcasm (`label`) based on the text of a comment on Reddit (`comment`).\n",
    "3. Plot the words/bigrams which a most predictive of sarcasm (you can use [eli5](https://github.com/TeamHG-Memex/eli5) for that)\n",
    "4. (optionally) add subreddits as new features to improve model performance. Apply here the Bag of Words approach, i.e. treat each subreddit as a new feature.\n",
    "\n",
    "### Part 1. Exploratory data analysis\n",
    "\n",
    "Distribution of lengths for sarcastic and normal comments is almost the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbd188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df[\"label\"] == 1, \"comment\"].str.len().apply(np.log1p).hist(\n",
    "    label=\"sarcastic\", alpha=0.5\n",
    ")\n",
    "train_df.loc[train_df[\"label\"] == 0, \"comment\"].str.len().apply(np.log1p).hist(\n",
    "    label=\"normal\", alpha=0.5\n",
    ")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f78c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import STOPWORDS, WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94922d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    background_color=\"black\",\n",
    "    stopwords=STOPWORDS,\n",
    "    max_words=200,\n",
    "    max_font_size=100,\n",
    "    random_state=17,\n",
    "    width=800,\n",
    "    height=400,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7e9d1a",
   "metadata": {},
   "source": [
    "Word cloud are nice, but not very useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9353f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "wordcloud.generate(str(train_df.loc[train_df[\"label\"] == 1, \"comment\"]))\n",
    "plt.imshow(wordcloud);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b704338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "wordcloud.generate(str(train_df.loc[train_df[\"label\"] == 0, \"comment\"]))\n",
    "plt.imshow(wordcloud);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab525c5",
   "metadata": {},
   "source": [
    "Let's analyze whether some subreddits are more \"sarcastic\" on average than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = train_df.groupby(\"subreddit\")[\"label\"].agg([np.size, np.mean, np.sum])\n",
    "sub_df.sort_values(by=\"sum\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ead58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df[sub_df[\"size\"] > 1000].sort_values(by=\"mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac89508",
   "metadata": {},
   "source": [
    "The same for authors doesn't yield much insight. Except for the fact that somebody's comments were sampled - we can see the same amounts of sarcastic and non-sarcastic comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99364912",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = train_df.groupby(\"author\")[\"label\"].agg([np.size, np.mean, np.sum])\n",
    "sub_df[sub_df[\"size\"] > 300].sort_values(by=\"mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1c2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = (\n",
    "    train_df[train_df[\"score\"] >= 0]\n",
    "    .groupby(\"score\")[\"label\"]\n",
    "    .agg([np.size, np.mean, np.sum])\n",
    ")\n",
    "sub_df[sub_df[\"size\"] > 300].sort_values(by=\"mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a618550",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = (\n",
    "    train_df[train_df[\"score\"] < 0]\n",
    "    .groupby(\"score\")[\"label\"]\n",
    "    .agg([np.size, np.mean, np.sum])\n",
    ")\n",
    "sub_df[sub_df[\"size\"] > 300].sort_values(by=\"mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c65873e",
   "metadata": {},
   "source": [
    "### Part 2. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9915fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build bigrams, put a limit on maximal number of features\n",
    "# and minimal word frequency\n",
    "tf_idf = TfidfVectorizer(ngram_range=(1, 2), max_features=50000, min_df=2)\n",
    "# multinomial logistic regression a.k.a softmax classifier\n",
    "logit = LogisticRegression(C=1, n_jobs=4, solver=\"lbfgs\", random_state=17, verbose=1)\n",
    "# sklearn's pipeline\n",
    "tfidf_logit_pipeline = Pipeline([(\"tf_idf\", tf_idf), (\"logit\", logit)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3989be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tfidf_logit_pipeline.fit(train_texts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d387986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "valid_pred = tfidf_logit_pipeline.predict(valid_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33802c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_valid, valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbc6a2e",
   "metadata": {},
   "source": [
    "### Part 3. Explaining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991cc864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(\n",
    "    actual,\n",
    "    predicted,\n",
    "    classes,\n",
    "    normalize=False,\n",
    "    title=\"Confusion matrix\",\n",
    "    figsize=(7, 7),\n",
    "    cmap=plt.cm.Blues,\n",
    "    path_to_save_fig=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    cm = confusion_matrix(actual, predicted).T\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"Predicted label\")\n",
    "    plt.xlabel(\"True label\")\n",
    "\n",
    "    if path_to_save_fig:\n",
    "        plt.savefig(path_to_save_fig, dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059732df",
   "metadata": {},
   "source": [
    "Confusion matrix is quite balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1065864",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    y_valid,\n",
    "    valid_pred,\n",
    "    tfidf_logit_pipeline.named_steps[\"logit\"].classes_,\n",
    "    figsize=(8, 8),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64322ee",
   "metadata": {},
   "source": [
    "Indeed, we can recognize some phrases indicative of sarcasm. Like \"yes sure\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84780ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "\n",
    "eli5.show_weights(\n",
    "    estimator=tfidf_logit_pipeline.named_steps[\"logit\"],\n",
    "    vec=tfidf_logit_pipeline.named_steps[\"tf_idf\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0270bb2",
   "metadata": {},
   "source": [
    "So sarcasm detection is easy.\n",
    "<img src=\"https://habrastorage.org/webt/1f/0d/ta/1f0dtavsd14ncf17gbsy1cvoga4.jpeg\" />\n",
    "\n",
    "### Part 4. Improving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0509d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = train_df[\"subreddit\"]\n",
    "train_subreddits, valid_subreddits = train_test_split(subreddits, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32008a45",
   "metadata": {},
   "source": [
    "We'll have separate Tf-Idf vectorizers for comments and for subreddits. It's possible to stick to a pipeline as well, but in that case it becomes a bit less straightforward. [Example](https://stackoverflow.com/questions/36731813/computing-separate-tfidf-scores-for-two-different-columns-using-sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07f84bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_texts = TfidfVectorizer(ngram_range=(1, 2), max_features=50000, min_df=2)\n",
    "tf_idf_subreddits = TfidfVectorizer(ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07da4b63",
   "metadata": {},
   "source": [
    "Do transformations separately for comments and subreddits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1823e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_texts = tf_idf_texts.fit_transform(train_texts)\n",
    "X_valid_texts = tf_idf_texts.transform(valid_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4717d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_texts.shape, X_valid_texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4941c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_subreddits = tf_idf_subreddits.fit_transform(train_subreddits)\n",
    "X_valid_subreddits = tf_idf_subreddits.transform(valid_subreddits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d54e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subreddits.shape, X_valid_subreddits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b88a40",
   "metadata": {},
   "source": [
    "Then, stack all features together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bade495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train = hstack([X_train_texts, X_train_subreddits])\n",
    "X_valid = hstack([X_valid_texts, X_valid_subreddits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee17709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5117a450",
   "metadata": {},
   "source": [
    "Train the same logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c274ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd797d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "valid_pred = logit.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_valid, valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398d9b11",
   "metadata": {},
   "source": [
    "As we can see, accuracy slightly increased.\n",
    "\n",
    "## Links:\n",
    "  - Machine learning library [Scikit-learn](https://scikit-learn.org/stable/index.html) (a.k.a. sklearn)\n",
    "  - Kernels on [logistic regression](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-2-classification) and its applications to [text classification](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-4-more-of-logit), also a [Kernel](https://www.kaggle.com/kashnitsky/topic-6-feature-engineering-and-feature-selection) on feature engineering and feature selection\n",
    "  - [Kaggle Kernel](https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle) \"Approaching (Almost) Any NLP Problem on Kaggle\"\n",
    "  - [ELI5](https://github.com/TeamHG-Memex/eli5) to explain model predictions"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   11,
   38,
   51,
   55,
   71,
   81,
   86,
   88,
   93,
   95,
   100,
   102,
   107,
   111,
   124,
   135,
   140,
   150,
   155,
   162,
   166,
   171,
   177,
   179,
   184,
   190,
   200,
   207,
   212,
   223,
   229,
   235,
   237,
   242,
   290,
   295,
   302,
   307,
   314,
   322,
   325,
   330,
   333,
   338,
   345,
   350,
   357,
   359,
   364,
   372,
   374,
   379,
   384,
   390,
   392
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}